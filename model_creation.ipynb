{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simpletransformers in c:\\users\\aatak\\anaconda3\\lib\\site-packages (0.63.9)\n",
      "Requirement already satisfied: datasets in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (0.23.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (1.1.3)\n",
      "Requirement already satisfied: transformers>=4.6.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (4.25.1)\n",
      "Requirement already satisfied: seqeval in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (1.2.2)\n",
      "Requirement already satisfied: streamlit in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (1.17.0)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (1.15.0)\n",
      "Requirement already satisfied: regex in c:\\users\\aatak\\appdata\\roaming\\python\\python38\\site-packages (from simpletransformers) (2022.10.31)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\aatak\\appdata\\roaming\\python\\python38\\site-packages (from simpletransformers) (0.1.97)\n",
      "Requirement already satisfied: requests in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (2.28.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (1.5.2)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (4.59.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\aatak\\appdata\\roaming\\python\\python38\\site-packages (from simpletransformers) (0.13.2)\n",
      "Requirement already satisfied: wandb>=0.10.32 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (0.13.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from simpletransformers) (1.22.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (0.11.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (10.0.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aatak\\appdata\\roaming\\python\\python38\\site-packages (from datasets->simpletransformers) (6.0)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (3.8.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (20.4)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from datasets->simpletransformers) (0.18.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aatak\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn->simpletransformers) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from scikit-learn->simpletransformers) (0.17.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from pandas->simpletransformers) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from pandas->simpletransformers) (2.8.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from transformers>=4.6.0->simpletransformers) (3.0.12)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (13.1.0)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (6.0.4)\n",
      "Requirement already satisfied: semver in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (2.13.0)\n",
      "Requirement already satisfied: toml in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (0.10.1)\n",
      "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (0.10.3)\n",
      "Requirement already satisfied: altair>=3.2.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (4.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (4.11.4)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (0.8.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\aatak\\appdata\\roaming\\python\\python38\\site-packages (from streamlit->simpletransformers) (4.4.0)\n",
      "Requirement already satisfied: pympler>=0.9 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (1.0.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (7.1.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (3.19.4)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (3.1.30)\n",
      "Requirement already satisfied: blinker>=1.0.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (1.5)\n",
      "Requirement already satisfied: tzlocal>=1.1 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (4.2)\n",
      "Requirement already satisfied: validators>=0.2 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (0.20.0)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (5.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (3.3.7)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (0.35.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.46.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (50.3.1.post20201107)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from requests->simpletransformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from requests->simpletransformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aatak\\appdata\\roaming\\python\\python38\\site-packages (from requests->simpletransformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from requests->simpletransformers) (2020.6.20)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: pathtools in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (1.13.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (1.3.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (5.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (20.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from packaging->datasets->simpletransformers) (2.4.7)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from rich>=10.11.0->streamlit->simpletransformers) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from rich>=10.11.0->streamlit->simpletransformers) (2.7.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (2.11.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit->simpletransformers) (3.4.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19->streamlit->simpletransformers) (4.0.10)\n",
      "Requirement already satisfied: tzdata; platform_system == \"Windows\" in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (2022.7)\n",
      "Requirement already satisfied: backports.zoneinfo; python_version < \"3.9\" in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.2.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit->simpletransformers) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from validators>=0.2->streamlit->simpletransformers) (4.4.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.17.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit->simpletransformers) (1.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\aatak\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit->simpletransformers) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"\n",
    "I use simpletransformers to finetune my BERT model\n",
    "Simpletransformers is a NLP library which is  designed to simplify the usage of Transformer models\n",
    "It is built on top of the Hugging Face and their Transformers library\n",
    "see https://simpletransformers.ai/about/ for more details\n",
    "\"\"\"\n",
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>3 milyon ile ön seçim vaadi mhp nin 10 olağan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>mesut_yılmaz yüce_divan da ceza alabilirdi pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>disko lar kaldırılıyor başbakan_yardımcısı ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>sarıgül anayasa_mahkemesi ne gidiyor mustafa_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>erdoğan idamın bir haklılık sebebi var demek ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat                                               text\n",
       "0  siyaset    3 milyon ile ön seçim vaadi mhp nin 10 olağan...\n",
       "1  siyaset    mesut_yılmaz yüce_divan da ceza alabilirdi pr...\n",
       "2  siyaset    disko lar kaldırılıyor başbakan_yardımcısı ar...\n",
       "3  siyaset    sarıgül anayasa_mahkemesi ne gidiyor mustafa_...\n",
       "4  siyaset    erdoğan idamın bir haklılık sebebi var demek ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading my dataset, \"A Benchmark Data for Turkish Text Categorization\" of Savaş Yıldırım\n",
    "# which is available at https://www.kaggle.com/datasets/savasy/ttc4900\n",
    "# It is a dataset based on the work of kemik group, http://www.kemik.yildiz.edu.tr/\n",
    "# The data are pre-processed for the text categorization \n",
    "train_data_df = pd.read_csv('C:/Users/aatak/Desktop/7allV03.csv', encoding='utf-8', header=None, names=['cat', 'text'])\n",
    "\n",
    "# note: I modified the data I downloaded from kaggle to delete the first row, which was \"cat, text\" as column headers.\n",
    "\n",
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['siyaset ' 'dunya ' 'ekonomi ' 'kultur ' 'saglik ' 'spor ' 'teknoloji ']\n"
     ]
    }
   ],
   "source": [
    "# print all the categories\n",
    "categories = train_data_df.cat.unique()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>3 milyon ile ön seçim vaadi mhp nin 10 olağan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>mesut_yılmaz yüce_divan da ceza alabilirdi pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>disko lar kaldırılıyor başbakan_yardımcısı ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>sarıgül anayasa_mahkemesi ne gidiyor mustafa_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>erdoğan idamın bir haklılık sebebi var demek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat                                               text  labels\n",
       "0  siyaset    3 milyon ile ön seçim vaadi mhp nin 10 olağan...       0\n",
       "1  siyaset    mesut_yılmaz yüce_divan da ceza alabilirdi pr...       0\n",
       "2  siyaset    disko lar kaldırılıyor başbakan_yardımcısı ar...       0\n",
       "3  siyaset    sarıgül anayasa_mahkemesi ne gidiyor mustafa_...       0\n",
       "4  siyaset    erdoğan idamın bir haklılık sebebi var demek ...       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We have to encode the category names to integers. I use pandas factorize method to do this\n",
    "and add the encoded category labels as a additional column, labels.\n",
    "for example, siyaset is now encoded as 0\n",
    "\"\"\"\n",
    "train_data_df['labels'] = pd.factorize(train_data_df.cat)[0]\n",
    "\n",
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We have to split the data into training and test groups so we can finetune the model with our\n",
    "train set and calculate its performance on our test set. I decided to have 80% training data and 20% test data\n",
    "\"\"\"\n",
    "\n",
    "train, test = train_test_split(train_data_df, test_size=0.2, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Experiments\n",
    "\n",
    "I use simpletransformers libraries ClassificationModel class to create my bert model and finetuning it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1 - Bert Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('bert', # it is a bert model\n",
    "                            'bert-base-multilingual-uncased', # choose which bert model \n",
    "                                                              # I want to load; I start with multilingual bert\n",
    "                                                              # which includes Turkish language\n",
    "                            num_labels=7, # we have 7 categories\n",
    "                            use_cuda=False, \n",
    "                            args={ # some additional arguments for model training, where to save the model, number of epochs etc\n",
    "                                'num_train_epochs': 3, # 3 epochs seemed to be enough in the experiments of other people using \n",
    "                                                      # bert for this type of task. We have to remember bert is a pretrained\n",
    "                                                      # model, we will just finetune it to our own dataset. so low number of\n",
    "                                                      # epochs are fine\n",
    "                                'overwrite_output_dir': True,\n",
    "                                'reprocess_input_data': True,\n",
    "                            }\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bb82db48cb49baa4f5b61ab3c2e701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573bbbfbd2c449de8cf506a0ac733ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f036a6ac64b94676aaf721d08b803e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c7aa3828f24d9aabc90f91b28bd982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5804f650f16413ca062b764714077fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1470, 0.4766262790647519)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b57c444ade4cc196357a55161a4f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8f48a05ca9434099a4d3f9f50da60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get evaluation from our library about the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(test)\n",
    "\n",
    "predictions = model_outputs.argmax(axis=1)\n",
    "actuals = test.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8948979591836734"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy score of my model\n",
    "accuracy_score(actuals, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is acceptable, but I'll try to improve by using bert-base-turkish-cased model in a second try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2 - Bert Turkish\n",
    "\n",
    "MDZ Digital Library team's Turkish BERT model is accessable at https://huggingface.co/dbmdz/bert-base-turkish-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('bert', # it is a bert model\n",
    "                            'dbmdz/bert-base-turkish-cased', # choose which bert model \n",
    "                                                              # I want to load; here I choose Turkish cased bert model\n",
    "                            num_labels=7, # we have 7 categories\n",
    "                            use_cuda=False, \n",
    "                            args={ # some additional arguments for model training, where to save the model, number of epochs etc\n",
    "                                'num_train_epochs': 3, # 3 epochs seemed to be enough in the experiments of other people using \n",
    "                                                      # bert for this type of task. We have to remember bert is a pretrained\n",
    "                                                      # model, we will just finetune it to our own dataset. so low number of\n",
    "                                                      # epochs are fine\n",
    "                                'overwrite_output_dir': True,\n",
    "                                'reprocess_input_data': True,\n",
    "                            }\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0d2ad3417f4e60b531bcbedb809d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2d0beca21d46fe9d5120337accbd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5549a4b18c5f4ef2bd2d356d25465d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2689be197b7949a8845dab932165b3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66defdf776eb4436b3552ec6dc690ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1470, 0.2991740818034072)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb02b88c6f624b3db7efadb966a965a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb010a5f30304726a3369edc812fe0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get evaluation from our library about the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(test)\n",
    "\n",
    "predictions = model_outputs.argmax(axis=1)\n",
    "actuals = test.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.939795918367347"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy score of my model\n",
    "accuracy_score(actuals, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the performance is better. This model can be improved by using more data, trying different BERT pretrained model or making other changes in the model in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
